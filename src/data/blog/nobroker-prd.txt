🧩 PRD v2.0 — NoBroker: Owner Performance Coach (OPC)

A non-AI, rule-based coaching layer that helps property owners fix underperforming listings across photos, copy/amenities, pricing, and responsiveness — to drive more qualified inquiries, faster.

⸻

0) Executive summary

Problem: owners can’t see why their listing underperforms; tenants encounter low-quality/stale listings; support gets “why no leads?” tickets; refunds/plan-churn follow.
Solution: embed a coach inside the owner experience that (1) benchmarks the listing vs local top performers, (2) flags the few highest-leverage fixes, and (3) tracks improvement.
North Star: % of owners achieving ≥+15% inquiries within 30 days after applying ≥1 coach fix.

Business Impact Model: Based on cohort analysis, a +15% lift in qualified inquiries is projected to correlate with a ~5-7% reduction in refund requests and a ~3-4% increase in subscription renewals for the engaged owner cohort. This translates to an estimated impact of reducing churn by X% and increasing renewal revenue by $Y per quarter, justifying the engineering investment.

⸻

1) Causal chain (systems view)

Owner listing quality ↑
 → Tenant trust & click intent ↑
   → Views → Inquiries → Visits → Closures ↑
     → Refund tickets ↓, Plan renewals ↑, Support load ↓

We intervene at the input levers (photos, copy/amenities, pricing, responsiveness) to shift the whole funnel.

⸻

2) Jobs To Be Done (JTBD) — replace personas

Situation (When…)	Struggle (I’m stuck because…)	Desired Progress (So I can…)	Design driver
Listing live 5–7 days, few inquiries	I don’t know what’s wrong	See the top 2–3 fixes and do them in <15 min	Health score + prioritized To-Dos
I paid for a plan	I’m anxious I won’t get ROI	See proof of improvement (views/inquiries)	Before/after deltas & milestones
Remote/busy	I can’t spend hours tweaking	Get simple, local-benchmarked suggestions	Local benchmarks, chips, templates
Getting chats but no visits	I don’t know what tenants value	Highlight missing selling points	Amenity gaps + copy templates
Many leads, low quality	I waste time	Nudge price/filters/eligibility to refine	Price sensitivity + pre-qual tips

2a) Design Principles & UX Vision

The user experience should feel like a helpful, private coach, not a stern critic. The tone should be encouraging, data-informed, and always focused on empowering the owner to succeed.
	•	Empowering, not Prescriptive: Give owners clear data and suggestions, but always leave them in control of the final decision.
	•	Simple & Actionable: Avoid jargon. Focus on a few, high-impact tasks. The user should know what to do in seconds.
	•	Celebrate Progress: Use positive reinforcement and visualize impact (e.g., "+20% views!") to build momentum and user confidence.
	•	Trustworthy & Transparent: Be clear about where data comes from (e.g., "based on 50 similar listings near you"). Never shame the user.

Non-Jobs (explicitly out):
	•	Auto-rewriting owner’s description (no AI for MVP). The backend architecture should, however, be modular enough to potentially incorporate ML models for features like photo-tagging or suggestion generation in future phases.
	•	Publicly shaming/“grading” owners.
	•	Changing search ranking (phase 3+ only).

⸻

3) Objectives, OKRs & North Star

North Star: % of owners achieving ≥+15% inquiries within 30 days after applying ≥1 coach fix.

Quarterly OKRs
	•	O1 (Quality): Raise proportion of listings meeting baseline quality bar.
	•	KR1: % listings with ≥8 photos → +20pp
	•	KR2: % listings with “local amenities” coverage ≥6 items → +25pp
	•	O2 (Conversion): Improve listing → inquiry efficiency.
	•	KR3: Median inquiries/view for OPC users → +15–25%
	•	O3 (Retention/Cost): Reduce refunds and support load.
	•	KR4: Plan refund tickets (owner) → –30%
	•	KR5: “Why no leads?” ticket volume → –30%

⸻

4) Hypotheses & experiments (falsifiable)
	•	H1: Showing max three prioritized fixes (not a long list) will increase fix adoption rate to ≥30% within 7 days.
Test: A/B: max-3 vs full-list; metric = completion of ≥1 fix.
	•	H2: A local benchmark view (PIN/locality) lifts owner trust and action more than generic tips.
Test: A/B: local vs citywide benchmarks; metric = fix adoption, CSAT.
	•	H3: A progress delta card (“+18% views, +2 inquiries”) sustains engagement.
Test: A/B: delta card vs no delta; metric = 30-day retention of OPC usage.
	•	H4: Owners act more on photos & price than on copy; sequencing them first boosts impact.
Test: Multivariate order; metric = inquiries delta at day-14.

⸻

5) Scope & prioritization (RICE)

Feature	Reach (0–5)	Impact (0–5)	Confidence (0–5)	Effort (1=low,5=high)	RICE
A. Local Benchmark Comparison	5	5	4	2	50
B. Photo Heuristics & Fixes	4	5	3	3	40
C. Description/Amenities Checker	4	4	4	3	35
D. Price Sensitivity & Range	3	4	3	4	22
E. Responsiveness Tracker	3	3	4	2	22

MVP (Phase-1): A+B+C.
Phase-2 (after validation): D+E.
Phase-3: incentives/visibility boosts; optional ranking tie-in.

⸻

6) Detailed requirements (by module)

6.1 Module A — Local Benchmark Comparison

Goal: show how the listing stacks up vs the top-performing 10 listings in same locality & property type.

Data inputs
	•	Locality/PIN, property type, BHK, furnished status.
	•	Top-10 active listings’ metrics (last 14 days): photo count, amenities count, price range, days-since-last-update, owner reply time.

UX
	•	Card at top: “Your Listing Health: 62/100”
	•	Table with color coding & “Fix” CTAs:
	•	Photos: 5 vs local avg 10 → Add photos
	•	Amenities covered: 6 vs 12 → Add amenities
	•	Price: ₹29k vs ideal ₹25–27k → Review price
	•	Last update: 30 days vs 10 → Refresh now

Acceptance criteria
	•	AC-A1: Benchmarks computed at locality (or fallback = micro-market) within last 7 days.
	•	AC-A2: Show at most 3 red/yellow gaps as “Top fixes”.
	•	AC-A3: “Refresh now” updates the listing timestamp, not content, and is rate-limited (1/day).

Edge cases
	•	<10 comps available: expand radius fallback; badge “limited sample”.
	•	New locality: show city-level benchmarks; transparency note.

⸻

6.2 Module B — Photo Heuristics & Fixes (non-AI rules)

Rules (configurable constants)
	•	Min photos threshold: 8 (baseline); good: 10–12.
	•	Mandatory coverage checks: living room, bedroom, kitchen, bathroom, exterior/balcony (if exists).
	•	Low-light heuristic: image avg brightness below threshold T (e.g., 0.35) → tag “Too dark”.
	•	Duplication check: same resolution + checksum match → tag “Duplicate”.
	•	Order rule: best-scored images first; bathrooms last.

UX
	•	Grid with badges: Too dark, Missing room, Duplicate, Low-res.
	•	“Top photo fixes” list (max 3):
	1.	Add kitchen photo;
	2.	Replace dark living-room photo;
	3.	Reorder: make Photo #4 your cover.
	•	Inspiration carousel: 5 “great photo” examples from same micro-market (blur owner names).

Acceptance criteria
	•	AC-B1: Heuristics run within 60s after upload; tags appear inline.
	•	AC-B2: “Replace” opens uploader; on save, tag clears.
	•	AC-B3: Owner may “Dismiss” a tag → system learns not to repeat for that image.

Edge cases
	•	Room not present → owner can mark “Not applicable”.
	•	Poor internet → lazy-load thumbnails; upload retries.

⸻

6.3 Module C — Description & Amenities Checker

Rule set
	•	Amenity catalog by locality (top 20 occurrences in high-conversion listings).
	•	Must-mention groups: transport (metro/bus <1km), water/power, security, parking, schools/parks/market.
	•	Copy hygiene: length ≥120 words; include 3 selling points & 2 proximity markers.

UX
	•	Missing-amenities chips: “Add: Covered parking”, “Add: Power backup”, “Add: Near XYZ Metro”.
	•	Template snippets (non-AI):
	•	“Bright 2BHK with balcony; 5-min walk to ___ Metro; 24×7 security, covered parking.”
	•	“Close to ___ School & ___ Park; modular kitchen, power backup.”
	•	Real-time “Description Score” (0–100) with hints (“mention proximity in meters/minutes”).

Acceptance criteria
	•	AC-C1: Chips reflect actual locality data; click = inserts tokenized text owner can edit.
	•	AC-C2: Score updates on keystroke (≤300ms budget).
	•	AC-C3: Prevent false claims: proximity chips only appear if geo-distance < threshold (e.g., 1 km).

Edge cases
	•	Geo unavailable → hide proximity chips; show generic amenity chips.
	•	Owner language preference → store bilingual templates (EN/HI/KAN).

⸻

(Phase-2) 6.4 Module D — Price Sensitivity & Range

Data
	•	Median & quartiles for comparable listings that closed or had high inquiry/view in last 60–90 days.

UX
	•	Slider with ideal band highlighted: “Local ideal: ₹25–27k; you: ₹29k (⚠ high)”.
	•	Tip pill: “Lower by ₹1–2k → +15–20% projected inquiries (based on comps).”
	•	“Update price” modal with confirmation & undo (24h).

Acceptance criteria
	•	AC-D1: Show sample size (n) and last-updated.
	•	AC-D2: Never suggest below platform minimums.

⸻

(Phase-2) 6.5 Module E — Responsiveness & Engagement

Signals
	•	Avg owner response time to first tenant message; % unanswered >24h; availability hours.

UX
	•	“Your avg reply: 36h; top performers: <12h.”
	•	Toggles: Instant push/SMS; quick-reply templates; “co-admin” contact.
	•	Tip pill: “Replies under 6h get 1.3× more visits.”

Acceptance criteria
	•	AC-E1: Compute response time daily; exclude tenant spam/duplicates.
	•	AC-E2: Allow “I’m traveling” status (temporarily pauses penalty hints).

⸻

6.6 Health Score & To-Do Summary
	•	Score composition: Photos 35%, Description 25%, Price 25%, Response 15% (weights configurable).
	•	To-Do (max 3): deterministic pick by highest impact * feasibility.
	•	Progress card: “Since fixes: +18% views, +2 inquiries (last 48h).”

Acceptance criteria
	•	AC-H1: Only 3 tasks shown at once; completing one reveals next in backlog.
	•	AC-H2: Progress delta only shown after ≥24h (to avoid noise).

⸻

7) Data model & instrumentation

Key tables/fields (simplified)
	•	ListingQualitySnapshot { listing_id, ts, photos_count, photo_flags[], amenities_count, has_proximity[], desc_len, price_band, response_time_avg, health_score }
	•	OwnerCoachAction { listing_id, ts, action_type, action_payload, completed:boolean }
	•	CoachExposure { listing_id, ts, variant, modules_shown[], to_dos_shown[], ctr }
	•	CoachOutcomes { listing_id, pre_window, post_window, views, inquiries, visits, closures }

Event taxonomy (core)
	•	coach_view_opened, coach_top_fix_clicked, coach_fix_completed, coach_dismissed,
	•	listing_photo_upload, listing_price_updated, listing_desc_updated,
	•	views_delta_computed, inquiries_delta_computed.

⸻

8) Analytics & dashboards
	•	Owner Funnel: exposure → click → fix → delta (%) → 30-day retention.
	•	Module Impact: per-module fix adoption & average delta.
	•	Refund/Support Overlay: monthly correlation: OPC usage vs refunds/tickets.
	•	Cohorts: by locality, property type, plan tier.

⸻

9) Rollout & experiments

Phase-1 (MVP): Cities: BLR + Pune. Users: new listings + renewals.
	•	A/B1: Coach (A+B+C) vs control.
	•	Success gates (2 weeks):
	•	≥25% of exposed owners complete ≥1 fix
	•	Median inquiries/view: +12% (interim)
	•	Owner CSAT on coach ≥4.0/5

Phase-2: add Pricing & Responsiveness; expand cities (Mumbai, Delhi NCR).
	•	A/B2: with vs without delta progress card.
	•	Gate: refund tickets −20% among OPC cohort by week-8.

Phase-3: incentives (visibility boosts for fast responders), optional search tie-in.

9a) Go-to-Market (GTM) Strategy

The launch will be phased to gather feedback and ensure a smooth rollout.
	•	Internal Readiness (Launch -2 weeks):
		•	Train Customer Support and Sales teams on the feature, armed with FAQs and scripts.
		•	Finalize analytics dashboards for monitoring.
	•	Beta Launch (Launch Day, 10% of new listings in BLR/Pune):
		•	Launch to a limited cohort to monitor for bugs and gather initial qualitative feedback via user interviews and session recordings.
		•	No external marketing communication.
	•	Full Launch (Launch +2 weeks):
		•	Roll out to 100% of active listings in launch cities.
		•	In-app notification campaign to drive discovery for existing owners.
		•	Email campaign to all owners announcing the new, free tool to help them get more leads.
		•	(Optional) Blog post detailing our commitment to owner success.

⸻

10) Risks & mitigations

Risk	Impact	Mitigation
Wrong suggestions (false positives)	Owner distrust	Inline “Not relevant” + feedback; tune thresholds weekly
Overwhelm	Inaction	Cap to-dos at 3; “Quick wins” labeling
Data sparsity in new localities	Weak benchmarks	Expand radius fallback; badge sample size
Gaming “refresh”	Cosmetic bumps only	Rate-limit; ignore refresh-only in ranking
Support confusion	Ticket spike early	Train scripts + in-product help; route tickets tagged “coach”


⸻

11) Content & copy (examples)
	•	Coach header: “Let’s get you more leads this week.”
	•	Photo tag: “Too dark — rooms look brighter with daylight. Try reshooting or reorder.”
	•	Amenity chip: “Add: 600m to Indiranagar Metro”
	•	Price tip: “Homes like yours close 17% faster at ₹26–27k.”
	•	Progress card: “Nice! After your changes: +21% views / +3 inquiries.”

Tone: helpful, non-judgmental, specific.

⸻

12) Compliance & privacy
	•	Owner-only score & hints (never public).
	•	Disclose benchmark logic (“based on similar nearby listings in last 14–60 days”).
	•	Store deltas aggregated; purge image diagnostics after 30 days.

⸻

13) Delivery plan & estimates (rough)
	•	Backend services (benchmarks, scoring, deltas): 2–3 sprints
	•	Frontend owner dashboard & modules A–C: 2 sprints
	•	Instrumentation & dashboards: 1 sprint (parallel)
	•	Phase-1 end-to-end (incl. QA/UAT): ~5–6 sprints
(assumes 1 FE, 1 BE, 1 full-stack, 1 QA, shared PM/Design)

⸻

14) Acceptance criteria (end-to-end MVP)
	•	Owners in BLR/Pune with active listings see coach card within 48h of listing going live.
	•	Coach displays Health score and ≤3 top fixes.
	•	Photo module tags dark/duplicate/missing with ≤5% error (QA dataset).
	•	Amenity chips appear only when geo-proximity and catalog available.
	•	Delta progress card appears within 24–48h after a fix; numbers match analytics backend within ±5%.
	•	Experiment data visible in dashboard, updated daily.

⸻

15) Open questions (for design/eng/legal)
	•	Should we allow tenants to lightly rate listing accuracy post-visit (private signal only)?
	•	Should we bundle an optional “photo day” (paid add-on) if photo quality remains poor after 2 nudges?
	•	What is the minimum sample size to show “price suggestion” with confidence? (propose n≥30 comps).
	•	Language localization scope for top 5 cities (EN + HI + local)?

⸻

TL;DR

This is JTBD-led, hypothesis-driven, experiment-ready, and detailed enough to implement without AI. If you want, I can now turn this into a polished Notion doc (headings, tables, callouts) and/or sketch wireframes for A/B/C modules so your portfolio piece looks production-grade.